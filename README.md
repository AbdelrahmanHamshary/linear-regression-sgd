

## ğŸ§  Overview

This repository contains **Assignment 1** of the *Artificial Intelligence Course (Fall 2026)*, featuring two main tasks:

1. ğŸ§© **10 Types of Machine Learning Optimizers** â€” Explained in detail in the provided PDF
2. ğŸ“ˆ **Linear Regression using Stochastic Gradient Descent (SGD)** â€” Implemented **from scratch**

---

## ğŸ¯ Project Description

A complete, educational yet **professionally structured** implementation of **Linear Regression with Stochastic Gradient Descent** â€” built entirely in **pure Python** (no external ML frameworks).
Includes modern **terminal visualization**, **colorful progress feedback**, and **rich performance charts**.

---

## ğŸ“Š Dataset Details

ğŸ“ **File:** `MultipleLR-Dataset.csv`
ğŸ“¦ **Samples:** 25â€ƒâ€ƒ**Columns:** 4â€ƒâ€ƒ**Features:** 3â€ƒâ€ƒ**Target:** 1

**Format:**

```
feature1, feature2, feature3, target
73,80,75,152
93,88,93,185
89,91,90,180
96,98,100,196
...
```

---

## âœ¨ Key Features

### âš™ï¸ Core Implementation

* ğŸ§® **Pure Python** (no ML libraries)
* ğŸ” **SGD Algorithm** from scratch
* ğŸ“ **Minâ€“Max Normalization** to [0, 1]
* ğŸ”€ **Train/Test Split** (80 / 20)
* ğŸ§  **Metrics:** RÂ², MSE, MAE

### ğŸ–¥ï¸ Professional Terminal Output

* ğŸ¨ **ANSI-colored messages**
* ğŸ”„ **Real-time progress updates**
* âœ… **Emoji status indicators**
* ğŸ“œ **Formatted & structured results**

### ğŸ“ˆ Visual Insights

* ğŸ“‰ **Training Loss Curve**
* ğŸ¯ **Predicted vs Actual (Train/Test)**
* ğŸ“Š **Residuals Analysis**
* âš–ï¸ **Feature Importance**
* ğŸ§© **Performance Comparison Dashboard**
* ğŸ§  **7 Elegant Plots** â€” modern, readable, and polished

---

## ğŸ› ï¸ Installation

### ğŸ§¾ Requirements

* Python 3.7 or newer
* Packages listed in `requirements.txt`

### ğŸ’» Setup

```bash
git clone <repo-url>
cd Assignment-1
pip install -r requirements.txt
```

---

## ğŸ§© Usage

### ğŸ§  Professional Mode (Recommended for Submission)

```bash
python main.py
```

> ğŸ’ Full visuals, colorized interface, and detailed analysis

> ğŸ§¾ Lightweight output, clear comments, no plots â€” ideal for discussion

---

## âš¡ Execution Flow

1. ğŸ“ **Data Collection** â€“ Load and validate dataset
2. âœ‚ï¸ **Preprocessing** â€“ Normalize and split data
3. ğŸ” **Exploration** â€“ Quick data overview
4. ğŸ§® **Model Definition** â€“ Linear Regression + SGD
5. ğŸš€ **Training** â€“ Gradient updates with live feedback
6. ğŸ“Š **Evaluation** â€“ RÂ², MSE, MAE metrics
7. ğŸ”§ **Optimization** â€“ Learning rate tuning
8. ğŸ¯ **Prediction** â€“ Show actual vs predicted results
9. ğŸ¨ **Visualization** â€“ Generate 7 professional charts

---

## ğŸ’¡ Sample Terminal Output

```
============================================================
ğŸ“ˆ Linear Regression with Stochastic Gradient Descent
============================================================

[1] Loading data... âœ“ 25 samples loaded

[2] Splitting data (80% train / 20% test)
    âœ“ Training: 20 samples
    âœ“ Testing : 5 samples

[3] Normalizing features... âœ“ Done

[4] Training model...
Iteration 100/1000, Loss = 45.2341
Iteration 200/1000, Loss = 23.5678
...
âœ“ Model training completed!

============================================================
ğŸ“Š RESULTS
============================================================

ğŸ”§ Model Parameters
  Weights: [0.1234, 0.5678, 0.9012]
  Bias   : 0.3456

ğŸ“ˆ Training Set
  RÂ² = 0.8765 | MSE = 12.34 | MAE = 2.79

ğŸ¯ Test Set
  RÂ² = 0.8234 | MSE = 15.67 | MAE = 3.12

âœ¨ Visualizing results...
  âœ… Loss Curve
  âœ… Predictions (Train/Test)
  âœ… Residuals
  âœ… Feature Importance
============================================================
ğŸ‰ Training completed successfully!
============================================================
```

---


## ğŸ§® Technical Overview

### âš™ï¸ Algorithm Details

| Parameter         | Description                   |
| ----------------- | ----------------------------- |
| **Algorithm**     | Stochastic Gradient Descent   |
| **Loss Function** | Mean Squared Error (MSE)      |
| **Learning Rate** | 0.01 (configurable)           |
| **Iterations**    | 1000 (configurable)           |
| **Weights Init.** | Random uniform in [-0.1, 0.1] |
| **Metrics**       | RÂ², MSE, MAE                  |

---

## ğŸ¨ Visualization Dashboard

> 7 fully-styled subplots with professional presentation

|  #  | Visualization              | Description                         |
| :-: | -------------------------- | ----------------------------------- |
| 1ï¸âƒ£ | **Loss Curve**             | Tracks model convergence            |
| 2ï¸âƒ£ | **Train Predictions**      | Actual vs Predicted (train data)    |
| 3ï¸âƒ£ | **Test Predictions**       | Actual vs Predicted (test data)     |
| 4ï¸âƒ£ | **Residuals**              | Shows prediction errors             |
| 5ï¸âƒ£ | **Feature Importance**     | Weight magnitudes                   |
| 6ï¸âƒ£ | **Error Distribution**     | Histogram + mean error line         |
| 7ï¸âƒ£ | **Performance Comparison** | RÂ² / MSE / MAE across train vs test |

ğŸ–Œï¸ **Design Highlights:**

* Consistent **blueâ€“redâ€“orange palette**
* **Emojis + titles** for visual flair
* **Labeled bars/points** with exact values
* **Perfect-prediction lines**
* **Subplot dashboards** with grids for clean readability

---

## ğŸ§  Advanced Configurations

| Variable               | Default | Description               |
| ---------------------- | ------- | ------------------------- |
| `LEARNING_RATE`        | `0.01`  | Controls update magnitude |
| `N_ITERATIONS`         | `1000`  | Number of training steps  |
| `TEST_SIZE`            | `0.2`   | Train/test ratio          |
| `RANDOM_SEED`          | `42`    | Ensures reproducibility   |
| `SHOW_PLOTS`           | `True`  | Toggle visual output      |
| `PRINT_PROGRESS_EVERY` | `100`   | Log frequency             |

---

ğŸ§© Robustness & Error Handling

* ğŸ§± **File checks** for dataset existence
* ğŸ” **Input validation** for shape & format
* ğŸ›¡ï¸ **Safe visualization handling**
* â³ **Progress bars & logging**
* ğŸ’¬ **Descriptive error messages**

---

ğŸ§® Performance Analysis

* ğŸ“‰ **Convergence tracking**
* ğŸ§  **Generalization check** on test data
* âš–ï¸ **Feature weight insights**
* ğŸ” **Residual and error analysis**
* ğŸ”§ **Learning rate tuning experiments**
* ğŸ§¾ **Statistical validation metrics**

---

âœ… Assignment Requirements Met

| Task          | Description                                 | Status                         |
| ------------- | ------------------------------------------- | ------------------------------ |
| ğŸ§© **Task 1** | *10 ML Optimizers explained*                | âœ… `Assignment-1.pdf`           |
| ğŸ“ˆ **Task 2** | *Linear Regression with SGD (from scratch)* | âœ… `main.py`  |

---

ğŸ‘¨â€ğŸ’» Author

**ğŸ‘¤ Name: Abdelrahman Hamdy Mustafa Ali El-Hamshary
**ğŸ“ Student ID:202002570
**ğŸ“˜ Course:Artificial Intelligence â€“ Fall 2025

---
